{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Archie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, target_size=(512, 512), transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.target_size = target_size\n",
    "        self.transform = transform\n",
    "\n",
    "        \n",
    "        image_extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\"]\n",
    "        image_files = []\n",
    "        for ext in image_extensions:\n",
    "            image_files.extend(glob(os.path.join(image_dir, ext)))\n",
    "            \n",
    "        mask_files = glob(os.path.join(mask_dir, \"*_mask.png\"))\n",
    "        \n",
    "        image_dict = {os.path.splitext(os.path.basename(f))[0]: f for f in image_files}\n",
    "        mask_dict = {os.path.splitext(os.path.basename(f))[0].replace('_mask', ''): f for f in mask_files}\n",
    "        \n",
    "        common_keys = set(image_dict.keys()) & set(mask_dict.keys())\n",
    "        self.pairs = [(image_dict[key], mask_dict[key]) for key in common_keys]\n",
    "        print(f\"Found {len(self.pairs)} valid image-mask pairs\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, mask_path = self.pairs[idx]\n",
    "\n",
    "        # Load image and mask in grayscale as NumPy arrays\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if image is None or mask is None:\n",
    "            raise FileNotFoundError(f\"Failed to load image or mask at {img_path} or {mask_path}\")\n",
    "\n",
    "        # Resize using cv2\n",
    "        image = cv2.resize(image, (self.target_size[1], self.target_size[0]), interpolation=cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, (self.target_size[1], self.target_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Apply augmentations with albumentations \n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "\n",
    "        # Ensure image and mask are NumPy arrays before converting to tensors\n",
    "        if not isinstance(image, np.ndarray) or not isinstance(mask, np.ndarray):\n",
    "            raise TypeError(f\"Expected NumPy arrays after transform, got {type(image)} for image and {type(mask)} for mask\")\n",
    "\n",
    "        # Manually convert NumPy arrays to PyTorch tensors\n",
    "        image = torch.from_numpy(image).float()  # Convert to float tensor\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        image = image.unsqueeze(0)  # Add channel dim: (H, W) -> (1, H, W)\n",
    "        mask = mask.unsqueeze(0)\n",
    "\n",
    "        # Normalize image to [0, 1]\n",
    "        image = image / 255.0\n",
    "\n",
    "        # Binarize mask, original range was 0, 255\n",
    "        mask = (mask > 127.5).float()\n",
    "\n",
    "        return image, mask, img_path, mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 2, dilation=2, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 2, dilation=2, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels=1, out_channels=1, features=[64, 128, 256, 512],\n",
    "    ):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        # self.bottleneck = nn.Sequential(\n",
    "        #         nn.Conv2d(features[-1], features[-1]*2, kernel_size=3, padding=2, dilation=2, bias=False),\n",
    "        #         nn.BatchNorm2d(features[-1]*2),\n",
    "        #         nn.ReLU(inplace=True),\n",
    "        #         nn.Conv2d(features[-1]*2, features[-1]*2, kernel_size=3, padding=2, dilation=2, bias=False),\n",
    "        #         nn.BatchNorm2d(features[-1]*2),\n",
    "        #         nn.ReLU(inplace=True)\n",
    "        #     )\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def compute_accuracy(outputs, masks):\n",
    "    preds = torch.sigmoid(outputs) > 0.5  # Apply sigmoid for prob, then threshold\n",
    "    correct = (preds == masks).float()\n",
    "    accuracy = correct.sum() / correct.numel()\n",
    "    return accuracy.item()\n",
    "\n",
    "# %%\n",
    "def evaluate_model(model, data_loader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks, _, _ in data_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            acc = compute_accuracy(outputs, masks)\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += acc\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_accuracy = total_accuracy / len(data_loader)\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlineConnectivityLoss(nn.Module):\n",
    "    def __init__(self, smooth=1, connectivity_weight=0.1):\n",
    "        super(OutlineConnectivityLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.connectivity_weight = connectivity_weight\n",
    "\n",
    "    def dice_loss(self, inputs, targets):\n",
    "        inputs_flat = inputs.view(-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        intersection = (inputs_flat * targets_flat).sum()\n",
    "        return 1 - (2. * intersection + self.smooth) / (inputs_flat.sum() + targets_flat.sum() + self.smooth)\n",
    "\n",
    "    def connectivity_penalty(self, inputs, targets):\n",
    "        # Penalty on overlapping regions\n",
    "        grad_h_overlap = torch.abs((inputs * targets)[:, :, 1:, :] - (inputs * targets)[:, :, :-1, :])\n",
    "        grad_w_overlap = torch.abs((inputs * targets)[:, :, :, 1:] - (inputs * targets)[:, :, :, :-1])\n",
    "\n",
    "        # Penalty on non-overlapping predicted regions (false positives)\n",
    "        non_overlap = inputs * (1 - targets)  # Predicted regions that don't overlap with ground truth\n",
    "        grad_h_non_overlap = torch.abs(non_overlap[:, :, 1:, :] - non_overlap[:, :, :-1, :])\n",
    "        grad_w_non_overlap = torch.abs(non_overlap[:, :, :, 1:] - non_overlap[:, :, :, :-1])\n",
    "\n",
    "        # Combine both penalties\n",
    "        penalty_overlap = (grad_h_overlap.sum() + grad_w_overlap.sum()) / inputs.numel()\n",
    "        penalty_non_overlap = (grad_h_non_overlap.sum() + grad_w_non_overlap.sum()) / inputs.numel()\n",
    "        return penalty_overlap + penalty_non_overlap\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        dice = self.dice_loss(inputs, targets)\n",
    "        penalty = self.connectivity_penalty(inputs, targets)\n",
    "        return dice + self.connectivity_weight * penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs, device):\n",
    "    model = model.to(device)\n",
    "    # total_positives = 0\n",
    "    # total_negatives = 0\n",
    "    # for _, mask, _, _ in train_loader:\n",
    "    #     mask_np = mask.numpy().flatten()\n",
    "    #     positives = np.sum(mask_np == 1)\n",
    "    #     negatives = np.sum(mask_np == 0)\n",
    "    #     total_positives += positives\n",
    "    #     total_negatives += negatives\n",
    "    # pos_weight_value = total_negatives / total_positives if total_positives > 0 else 1.0\n",
    "    # print(f\"Using pos_weight: {pos_weight_value:.2f}\")\n",
    "    pos_weight = torch.tensor([2.0]).to(device)\n",
    "    \n",
    "    criterion_bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    criterion_conn = OutlineConnectivityLoss(smooth=1, connectivity_weight=0.1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
    "        for images, masks, _, _ in train_loop:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss_bce = criterion_bce(outputs, masks)\n",
    "            loss_conn = criterion_conn(outputs, masks)\n",
    "            loss = 0.5 * loss_bce + 0.5 * loss_conn  # Combine BCE and Dice+Connectivity\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks, _, _ in train_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                loss_bce = criterion_bce(outputs, masks)\n",
    "                loss_conn = criterion_conn(outputs, masks)\n",
    "                loss = 0.5 * loss_bce + 0.5 * loss_conn\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 valid image-mask pairs\n",
      "Found 244 valid image-mask pairs\n",
      "Training samples: 195, Test samples: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.6988, Val Loss: 2.7976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 49/49 [00:25<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train Loss: 0.6133, Val Loss: 2.4367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 49/49 [00:25<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train Loss: 0.5761, Val Loss: 2.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 49/49 [00:25<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train Loss: 0.5452, Val Loss: 2.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 49/49 [00:25<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train Loss: 0.5177, Val Loss: 1.9982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 49/49 [00:25<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Train Loss: 0.4951, Val Loss: 1.8898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 49/49 [00:25<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Train Loss: 0.4731, Val Loss: 1.8241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Train Loss: 0.4558, Val Loss: 1.7847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 49/49 [00:28<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Train Loss: 0.4356, Val Loss: 1.6345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 49/49 [00:25<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Train Loss: 0.4173, Val Loss: 1.6230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Train Loss: 0.3992, Val Loss: 1.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Train Loss: 0.3806, Val Loss: 1.4902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 49/49 [00:26<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Train Loss: 0.3651, Val Loss: 1.4113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Train Loss: 0.3514, Val Loss: 1.3677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 49/49 [00:25<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Train Loss: 0.3378, Val Loss: 1.2798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Train Loss: 0.3207, Val Loss: 1.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 49/49 [00:25<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Train Loss: 0.3047, Val Loss: 1.1854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Train Loss: 0.2961, Val Loss: 1.1153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Train Loss: 0.2815, Val Loss: 1.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Train Loss: 0.2679, Val Loss: 0.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Train Loss: 0.2551, Val Loss: 1.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Train Loss: 0.2542, Val Loss: 0.9353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Train Loss: 0.2452, Val Loss: 0.9496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Train Loss: 0.2304, Val Loss: 0.9181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 49/49 [00:25<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Train Loss: 0.2274, Val Loss: 0.9036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Train Loss: 0.2237, Val Loss: 0.8290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 49/49 [00:25<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Train Loss: 0.2126, Val Loss: 0.8168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Train Loss: 0.2085, Val Loss: 0.8048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Train Loss: 0.2003, Val Loss: 0.7432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 49/49 [00:25<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Train Loss: 0.1909, Val Loss: 0.7370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 49/49 [00:25<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Train Loss: 0.1879, Val Loss: 0.7078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 49/49 [00:25<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 - Train Loss: 0.1821, Val Loss: 0.7120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 49/49 [00:25<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Train Loss: 0.1796, Val Loss: 0.6654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 49/49 [00:25<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 - Train Loss: 0.1766, Val Loss: 0.7202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Train Loss: 0.1797, Val Loss: 0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 - Train Loss: 0.1702, Val Loss: 0.6711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 49/49 [00:25<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Train Loss: 0.1691, Val Loss: 0.6445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 49/49 [00:25<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 - Train Loss: 0.1662, Val Loss: 0.6198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Train Loss: 0.1622, Val Loss: 0.6215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Train Loss: 0.1553, Val Loss: 0.5936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 49/49 [00:25<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 - Train Loss: 0.1522, Val Loss: 0.5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 - Train Loss: 0.1532, Val Loss: 0.5631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 49/49 [00:25<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 - Train Loss: 0.1474, Val Loss: 0.5803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 49/49 [00:25<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 - Train Loss: 0.1466, Val Loss: 0.5560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 49/49 [00:25<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 - Train Loss: 0.1518, Val Loss: 0.5902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 49/49 [00:25<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 - Train Loss: 0.1453, Val Loss: 0.5458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Train Loss: 0.1451, Val Loss: 0.5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 49/49 [00:28<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 - Train Loss: 0.1478, Val Loss: 0.5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 49/49 [00:26<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Train Loss: 0.1408, Val Loss: 0.5390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 49/49 [00:26<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.1370, Val Loss: 0.5447\n",
      "Model saved as edge_segmentation_model.pth\n"
     ]
    }
   ],
   "source": [
    "IMAGE_HEIGHT = 512\n",
    "IMAGE_WIDTH = 512\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Rotate(limit=35, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.1),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "image_dir = \"images/\"\n",
    "mask_dir = \"outputMasks/\"\n",
    "batch_size = 4\n",
    "num_epochs = 80\n",
    "test_split = 0.2  # 20% for testing\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data loading\n",
    "train_dataset = EdgeSegmentationDataset(image_dir, mask_dir, transform=train_transform)\n",
    "val_dataset = EdgeSegmentationDataset(image_dir, mask_dir, transform=val_transforms)\n",
    "\n",
    "# Train-test split on indices\n",
    "indices = list(range(len(train_dataset)))\n",
    "train_indices, test_indices = train_test_split(\n",
    "    indices, test_size=test_split, random_state=42\n",
    ")\n",
    "\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(val_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_subset)}, Test samples: {len(val_subset)}\")\n",
    "\n",
    "# Model\n",
    "model = UNET().to(device)\n",
    "\n",
    "# Train and test\n",
    "model = train_model(model, train_loader, test_loader, num_epochs=num_epochs, device=device)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"edge_segmentation_model.pth\")\n",
    "print(\"Model saved as edge_segmentation_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import active_contour\n",
    "model.eval()\n",
    "test_samples = []\n",
    "with torch.no_grad():\n",
    "    for images, masks, img_paths, mask_paths in test_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = torch.sigmoid(outputs)  # Ensure outputs are probabilities (0-1)\n",
    "        test_samples.extend(zip(images.cpu(), masks.cpu(), outputs.cpu(), img_paths, mask_paths))\n",
    "        if len(test_samples) >= 5:  # Limit to 5\n",
    "            break\n",
    "\n",
    "def create_outer_frame_contour(image_shape, border_offset=5, num_points=100):\n",
    "    h, w = image_shape\n",
    "    # Define the rectangle just inside the image borders\n",
    "    top_left = (border_offset, border_offset)\n",
    "    top_right = (w - border_offset, border_offset)\n",
    "    bottom_right = (w - border_offset, h - border_offset)\n",
    "    bottom_left = (border_offset, h - border_offset)\n",
    "\n",
    "    # Create points along each side of the rectangle\n",
    "    points_per_side = num_points // 4  # Distribute points across 4 sides\n",
    "    top = np.linspace(top_left, top_right, points_per_side)\n",
    "    right = np.linspace(top_right, bottom_right, points_per_side)\n",
    "    bottom = np.linspace(bottom_right, bottom_left, points_per_side)\n",
    "    left = np.linspace(bottom_left, top_left, points_per_side)\n",
    "\n",
    "    # Concatenate the points to form a closed contour\n",
    "    initial_contour = np.vstack([top, right, bottom, left])\n",
    "    return initial_contour\n",
    "\n",
    "for i, (image, true_mask, pred, img_path, mask_path) in enumerate(test_samples[:5]):\n",
    "    image = image.permute(1, 2, 0).numpy()  # CHW to HWC\n",
    "    \n",
    "    # True mask processing\n",
    "    true_mask_np = true_mask.squeeze().numpy()  # Remove channel dim\n",
    "    print(f\"Sample {i+1} - True Mask Stats: min={true_mask_np.min():.2f}, max={true_mask_np.max():.2f}, mean={true_mask_np.mean():.2f}\")\n",
    "    true_mask_display = (true_mask_np * 255).astype(np.uint8)  # Scale to 0-255\n",
    "    \n",
    "    # Predicted mask processing\n",
    "    pred_np = pred.squeeze().numpy()  # Remove channel dim\n",
    "    print(f\"Sample {i+1} - Pred Mask Stats: min={pred_np.min():.2f}, max={pred_np.max():.2f}, mean={pred_np.mean():.2f}\")\n",
    "    pred_mask_display = (pred_np * 255).astype(np.uint8)  \n",
    "    # pred_mask_display = (pred_np > 0.5 ).astype(np.uint8) * 255  \n",
    "\n",
    "    contours_pred, _ = cv2.findContours(pred_mask_display, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    pred_contour = max(contours_pred, key=cv2.contourArea).squeeze() if contours_pred else None\n",
    "\n",
    "    if pred_contour is not None:\n",
    "        print(f\"Sample {i+1} - pred_contour shape: {pred_contour.shape}\")\n",
    "        # Ensure pred_contour has the correct shape (N, 2)\n",
    "        if len(pred_contour.shape) == 1:  # If 1D, reshape it\n",
    "            pred_contour = pred_contour.reshape(-1, 2)\n",
    "            print(\"No contour found\")\n",
    "        elif pred_contour.shape[1] != 2:  # If shape is not (N, 2), handle error\n",
    "            print(f\"Sample {i+1} - Invalid pred_contour shape: {pred_contour.shape}\")\n",
    "            pred_contour = None\n",
    "\n",
    "\n",
    "        if pred_contour is not None:\n",
    "            if not np.array_equal(pred_contour[0], pred_contour[-1]):\n",
    "                print(f\"Sample {i+1} - Initial contour not closed, forcing closure\")\n",
    "                pred_contour = np.vstack([pred_contour, pred_contour[0]])\n",
    "    \n",
    "    outer_contour = create_outer_frame_contour(pred_mask_display.shape, border_offset=5, num_points=200)\n",
    "\n",
    "    if outer_contour is not None:\n",
    "\n",
    "        # Parameters for active_contour:\n",
    "        # - alpha: Controls the snake's elasticity (length penalty, positive to shrink)\n",
    "        # - beta: Controls the snake's rigidity (smoothness penalty)\n",
    "        # - gamma: Step size for iteration\n",
    "        try:\n",
    "            snake_contour = active_contour(\n",
    "                pred_mask_display,  \n",
    "                outer_contour,     \n",
    "                alpha=0.05,       # Positive alpha to encourage shrinking\n",
    "                beta=.01,          # Rigidity for smoothness\n",
    "                gamma=0.001,      # Step size\n",
    "            )\n",
    "            # Ensure the snake contour is closed\n",
    "            snake_contour = np.vstack([snake_contour, snake_contour[0]])\n",
    "        except Exception as e:\n",
    "            print(f\"Sample {i+1} - Active contour failed: {str(e)}\")\n",
    "            snake_contour = None\n",
    "    else:\n",
    "        snake_contour = None\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title(\"True Mask\")\n",
    "    plt.imshow(true_mask_display, cmap='gray', vmin=0, vmax=255)  \n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.imshow(pred_mask_display, cmap='gray', vmin=0, vmax=255)  \n",
    "    if pred_contour is not None:\n",
    "        plt.plot(pred_contour[:, 0], pred_contour[:, 1], 'b-', linewidth=2, label='Initial Contour')  # Blue for initial contour\n",
    "    if snake_contour is not None:\n",
    "        plt.plot(snake_contour[:, 0], snake_contour[:, 1], 'r-', linewidth=2, label='Snake Contour')  # Blue for initial contour\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "    \n",
    "    plt.suptitle(f\"Sample {i+1}: {os.path.basename(img_path)}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
